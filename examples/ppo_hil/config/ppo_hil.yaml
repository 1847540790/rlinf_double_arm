# PPO with Human-in-the-Loop (HIL) Configuration
# Human can intervene during training to provide corrections

# HIL settings
hil:
  enable: true  # HIL ENABLED
  input_device: "keyboard"  # Options: "keyboard", "vivetracker", "spacemouse", "mock"
  
  # BC loss weight - how much to trust human demonstrations
  # Higher = more imitation, Lower = more RL
  bc_weight: 0.1
  
  # Boost advantage for intervention steps
  # Higher = human actions are considered "much better"
  intervention_advantage_boost: 1.5

# PPO hyperparameters
ppo:
  clip_ratio: 0.2
  vf_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  gamma: 0.99
  gae_lambda: 0.95
  
  # Training schedule
  num_epochs: 10
  minibatch_size: 64
  learning_rate: 3.0e-4

# Rollout settings
rollout:
  rollout_steps: 2048
  num_envs: 1

# Environment settings
env:
  simulator_type: "mock"  # or "gym", "maniskill", "libero", etc.
  max_episode_steps: 200
  obs_dim: 14
  action_dim: 7

# Logging
logging:
  log_interval: 10
  eval_interval: 100
  save_interval: 1000
  checkpoint_dir: "./results/ppo_hil/checkpoints"
  log_path: "./results/ppo_hil"
  experiment_name: "ppo_hil_test"

# Training
max_steps: 100000

# ============================================
# HIL Keyboard Controls (when input_device: "keyboard"):
# ============================================
# Hold SHIFT + use these keys to intervene:
#   W/S: Forward/Backward (X axis)
#   A/D: Left/Right (Y axis)
#   Q/E: Up/Down (Z axis)
#   I/K: Pitch rotation
#   J/L: Yaw rotation
#   U/O: Roll rotation
#   SPACE: Toggle gripper
# 
# Release SHIFT to let the policy take over again.
# ============================================

