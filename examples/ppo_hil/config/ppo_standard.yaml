# Standard PPO Configuration (No HIL)
# Use this for baseline training without human intervention

# HIL settings
hil:
  enable: false  # HIL DISABLED - standard PPO

# PPO hyperparameters
ppo:
  clip_ratio: 0.2
  vf_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  gamma: 0.99
  gae_lambda: 0.95
  
  # Training schedule
  num_epochs: 10
  minibatch_size: 64
  learning_rate: 3.0e-4

# Rollout settings
rollout:
  rollout_steps: 2048
  num_envs: 1

# Environment settings
env:
  simulator_type: "mock"  # or "gym", "maniskill", "libero", etc.
  max_episode_steps: 200
  obs_dim: 14
  action_dim: 7

# Logging
logging:
  log_interval: 10
  eval_interval: 100
  save_interval: 1000
  checkpoint_dir: "./results/ppo_standard/checkpoints"
  log_path: "./results/ppo_standard"
  experiment_name: "ppo_standard_test"

# Training
max_steps: 100000

